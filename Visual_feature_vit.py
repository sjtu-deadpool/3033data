# -*- coding: utf-8 -*-
"""Visual_feature_ViT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1afQ6FcowCgarTuhDGI5ZbvhoJG5ge5C1
"""

!pip install cinemagoer
!pip install selenium
!pip install undetected_chromedriver
!pip install serpapi

import pandas as pd
import numpy as np
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import torch.optim as optim
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from collections import Counter
import json
import re
from tqdm import tqdm

# Set paths
DATA_DIR = '..'  # Path adjusted to be one level up

def load_and_merge_data():
    """Load MovieLens data and merge with IMDb/TMDB data if available"""
    print("Loading datasets...")

    # Load MovieLens CSVs
    movies_path = os.path.join(DATA_DIR, 'movies.csv')
    ratings_path = os.path.join(DATA_DIR, 'ratings.csv')
    links_path = os.path.join(DATA_DIR, 'links.csv')
    tags_path = os.path.join(DATA_DIR, 'tags.csv')

    try:
        movies_df = pd.read_csv(movies_path)
        print(f"Loaded {len(movies_df)} movies from MovieLens")
    except Exception as e:
        print(f"Error loading movies.csv: {e}")
        movies_df = pd.DataFrame()

    try:
        ratings_df = pd.read_csv(ratings_path)
        print(f"Loaded {len(ratings_df)} ratings from MovieLens")
    except Exception as e:
        print(f"Error loading ratings.csv: {e}")
        ratings_df = pd.DataFrame()

    try:
        links_df = pd.read_csv(links_path)
        print(f"Loaded {len(links_df)} link records from MovieLens")
    except Exception as e:
        print(f"Error loading links.csv: {e}")
        links_df = pd.DataFrame()

    try:
        tags_df = pd.read_csv(tags_path)
        print(f"Loaded {len(tags_df)} tags from MovieLens")
    except Exception as e:
        print(f"Error loading tags.csv: {e}")
        tags_df = pd.DataFrame()

    # Try to load IMDb/TMDB enriched data if available
    try:
        imdb_tmdb_df = pd.read_csv("top_movies.csv")
        print(f"Loaded {len(imdb_tmdb_df)} movies from IMDb/TMDB dataset")
        has_external_data = True
    except Exception as e:
        print(f"IMDb/TMDB dataset not found or error: {e}")
        imdb_tmdb_df = pd.DataFrame()
        has_external_data = False

    # Merge datasets if we have all necessary components
    if not movies_df.empty and not links_df.empty:
        # Merge movies with links to get IMDb IDs
        merged_df = pd.merge(movies_df, links_df, on='movieId', how='left')

        # Format IMDb IDs properly
        if 'imdbId' in merged_df.columns:
            merged_df['imdbId'] = merged_df['imdbId'].astype(str).str.zfill(7)
            merged_df['imdbId'] = 'tt' + merged_df['imdbId']

        # Try to merge with IMDb/TMDB data if available
        if has_external_data and 'IMDb_ID' in imdb_tmdb_df.columns:
            print("Merging with IMDb/TMDB data...")
            merged_df = pd.merge(merged_df, imdb_tmdb_df, left_on='imdbId', right_on='IMDb_ID', how='left')
            print(f"Dataset after merging has {len(merged_df)} rows")
    else:
        merged_df = movies_df if not movies_df.empty else imdb_tmdb_df

    # Add user data if available
    user_df = None
    try:
        user_path = os.path.join(DATA_DIR, 'users.csv')
        user_df = pd.read_csv(user_path)
        print(f"Loaded {len(user_df)} users")
    except Exception as e:
        print(f"User data not found or error: {e}")
        # Create basic user data from ratings if available
        if not ratings_df.empty:
            print("Creating basic user data from ratings")
            user_df = pd.DataFrame({'userId': ratings_df['userId'].unique()})

    return {
        'movies': merged_df,
        'ratings': ratings_df,
        'tags': tags_df,
        'users': user_df
    }

def extract_year_from_title(movies_df):
    """Extract year from movie titles and create a separate column"""
    if 'title' in movies_df.columns:
        # Extract year using regex pattern (4 digits inside parentheses at the end)
        movies_df['year'] = movies_df['title'].str.extract(r'$(\d{4})$').astype('float')
        # Remove year from title
        movies_df['title_no_year'] = movies_df['title'].str.replace(r'\s*$\d{4}$\s*', '', regex=True)
    return movies_df

def process_movie_features(movies_df, ratings_df=None, tags_df=None):
    """
    Process and create features from movie data including:
    - Extract year from title
    - Process genres with one-hot encoding
    - Calculate movie statistics from ratings
    - Process keywords and tags
    - Add all possible categorical features for one-hot encoding
    """
    print("Processing movie features...")

    # Make a copy to avoid modifying the original
    movies_df = movies_df.copy()

    # Extract year from title if not already available
    if 'year' not in movies_df.columns and 'title' in movies_df.columns:
        movies_df = extract_year_from_title(movies_df)

    # Process genres if available
    if 'genres' in movies_df.columns:
        # Get all unique genres
        all_genres = set()
        for genres in movies_df['genres'].dropna():
            if '|' in str(genres):
                all_genres.update(genres.split('|'))
            else:
                all_genres.add(genres)

        print(f"Found {len(all_genres)} unique genres")

        # Create one-hot encoded columns for each genre
        for genre in all_genres:
            if genre and genre != '(no genres listed)':
                movies_df[f'genre_{genre}'] = movies_df['genres'].apply(
                    lambda x: 1 if isinstance(x, str) and genre in x.split('|') else 0
                )

    # Add rating statistics if ratings data is available
    if ratings_df is not None and not ratings_df.empty:
        print("Calculating movie rating statistics...")
        rating_stats = ratings_df.groupby('movieId').agg({
            'rating': ['count', 'mean', 'std', 'min', 'max']
        }).reset_index()
        rating_stats.columns = ['movieId', 'rating_count', 'rating_mean', 'rating_std', 'rating_min', 'rating_max']

        # Fill NaN values in standard deviation (happens when there's only one rating)
        rating_stats['rating_std'] = rating_stats['rating_std'].fillna(0)

        # Merge with movies dataframe
        movies_df = pd.merge(movies_df, rating_stats, on='movieId', how='left')

    # Process tags if available
    if tags_df is not None and not tags_df.empty:
        print("Processing movie tags...")
        # Aggregate tags for each movie
        movie_tags = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()

        # Create TF-IDF features for tags
        tfidf = TfidfVectorizer(max_features=200, stop_words='english', min_df=5)

        if len(movie_tags) > 0:
            tag_features = tfidf.fit_transform(movie_tags['tag'].fillna(''))
            tag_feature_names = [f'tag_{name}' for name in tfidf.get_feature_names_out()]

            tag_df = pd.DataFrame(tag_features.toarray(), columns=tag_feature_names)
            tag_df['movieId'] = movie_tags['movieId'].values

            # Merge tags with movies
            movies_df = pd.merge(movies_df, tag_df, on='movieId', how='left')

    # Process additional TMDB/IMDb features if available
    # Most of these can be one-hot encoded if they are categorical
    categorical_columns = [
        'Kind', 'Color_Info', 'Sound_Mix', 'TMDB_Status', 'TMDB_Original_Language'
    ]

    for col in categorical_columns:
        if col in movies_df.columns:
            # For pipe-separated values, split and create one-hot columns
            if movies_df[col].dtype == 'object' and movies_df[col].str.contains('|', na=False).any():
                unique_values = set()
                for values in movies_df[col].dropna():
                    unique_values.update(values.split('|'))

                for value in unique_values:
                    if value:
                        movies_df[f'{col}_{value}'] = movies_df[col].apply(
                            lambda x: 1 if isinstance(x, str) and value in x.split('|') else 0
                        )
            # For single values, use direct one-hot encoding
            elif not pd.api.types.is_numeric_dtype(movies_df[col]):
                for value in movies_df[col].dropna().unique():
                    if value:
                        movies_df[f'{col}_{value}'] = (movies_df[col] == value).astype(int)

    # Process countries if available
    if 'Countries' in movies_df.columns:
        unique_countries = set()
        for countries in movies_df['Countries'].dropna():
            if isinstance(countries, str) and '|' in countries:
                unique_countries.update(countries.split('|'))
            elif isinstance(countries, str):
                unique_countries.add(countries)

        # Limit to top N countries to avoid too many features
        country_counts = Counter()
        for countries in movies_df['Countries'].dropna():
            if isinstance(countries, str):
                for country in countries.split('|'):
                    country_counts[country] += 1

        top_countries = [country for country, _ in country_counts.most_common(20)]

        for country in top_countries:
            if country:
                movies_df[f'country_{country}'] = movies_df['Countries'].apply(
                    lambda x: 1 if isinstance(x, str) and country in x.split('|') else 0
                )

    # Process languages if available
    if 'Languages' in movies_df.columns:
        top_languages = [lang for lang, _ in Counter([
            l for langs in movies_df['Languages'].dropna()
            for l in (langs.split('|') if isinstance(langs, str) else [])
        ]).most_common(15)]

        for lang in top_languages:
            if lang:
                movies_df[f'language_{lang}'] = movies_df['Languages'].apply(
                    lambda x: 1 if isinstance(x, str) and lang in x.split('|') else 0
                )

    # Process directors, limited to top directors
    if 'Directors' in movies_df.columns:
        top_directors = [dir for dir, _ in Counter([
            d for dirs in movies_df['Directors'].dropna()
            for d in (dirs.split('|') if isinstance(dirs, str) else [])
        ]).most_common(30)]

        for director in top_directors:
            if director:
                movies_df[f'director_{director}'] = movies_df['Directors'].apply(
                    lambda x: 1 if isinstance(x, str) and director in x.split('|') else 0
                )

    # Convert numerical features
    numerical_columns = [
        'Year', 'year', 'Runtime_Minutes', 'Votes', 'Rating', 'Top_250_Rank',
        'TMDB_Runtime', 'TMDB_Vote_Average', 'TMDB_Vote_Count', 'TMDB_Popularity',
        'TMDB_Budget', 'TMDB_Revenue'
    ]

    for col in numerical_columns:
        if col in movies_df.columns:
            # Convert to numeric, coercing errors to NaN
            movies_df[col] = pd.to_numeric(movies_df[col], errors='coerce')

            # Fill missing values with median
            if movies_df[col].isnull().sum() > 0:
                median_val = movies_df[col].median()
                movies_df[col] = movies_df[col].fillna(median_val)

    print(f"Processed features: {movies_df.shape[1]} columns for {len(movies_df)} movies")
    return movies_df

def process_user_features(user_df, ratings_df=None):
    """
    Process user features including:
    - One-hot encoding of gender, age groups, occupation
    - Add user statistics from ratings data
    """
    print("Processing user features...")

    if user_df is None or user_df.empty:
        if ratings_df is not None and not ratings_df.empty:
            # Create basic user dataframe from ratings
            user_df = pd.DataFrame({'userId': ratings_df['userId'].unique()})
            print(f"Created basic user data for {len(user_df)} users from ratings")
        else:
            print("No user data available")
            return None

    # Make a copy to avoid modifying original
    user_features = user_df.copy()

    # Process categorical features if available
    categorical_cols = ['gender', 'occupation']
    for col in categorical_cols:
        if col in user_features.columns:
            for value in user_features[col].dropna().unique():
                if value:
                    user_features[f'{col}_{value}'] = (user_features[col] == value).astype(int)

    # Process age into bins if available
    if 'age' in user_features.columns:
        # Define age bins and labels
        bins = [0, 18, 25, 35, 45, 55, 65, 100]
        labels = ['<18', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']

        # Create age groups
        user_features['age_group'] = pd.cut(
            pd.to_numeric(user_features['age'], errors='coerce'),
            bins=bins,
            labels=labels,
            right=False
        )

        # One-hot encode age groups
        for label in labels:
            user_features[f'age_group_{label}'] = (user_features['age_group'] == label).astype(int)

    # Add user statistics from ratings if available
    if ratings_df is not None and not ratings_df.empty:
        # Calculate various statistics per user
        user_stats = ratings_df.groupby('userId').agg({
            'rating': ['count', 'mean', 'std', 'min', 'max'],
            'movieId': 'nunique'  # Number of unique movies rated
        }).reset_index()

        # Flatten the multi-level columns
        user_stats.columns = ['userId', 'rating_count', 'rating_mean', 'rating_std',
                             'rating_min', 'rating_max', 'unique_movies_rated']

        # Fill NaN values in std (happens when there's only one rating)
        user_stats['rating_std'] = user_stats['rating_std'].fillna(0)

        # Merge with user features
        user_features = pd.merge(user_features, user_stats, on='userId', how='left')

        # Fill missing values
        numerical_cols = ['rating_count', 'rating_mean', 'rating_std', 'rating_min',
                          'rating_max', 'unique_movies_rated']
        for col in numerical_cols:
            if col in user_features.columns:
                user_features[col] = user_features[col].fillna(user_features[col].median())

    print(f"Processed user features: {user_features.shape[1]} columns for {len(user_features)} users")
    return user_features

def create_mlp_embeddings(movie_features_df, user_features_df, movie_dim=128, user_dim=32):
    """
    Create MLP embeddings for movies and users using an autoencoder approach.
    Parameters:
    - movie_features_df: DataFrame with processed movie features
    - user_features_df: DataFrame with processed user features
    - movie_dim: Dimension of movie embedding (default: 128)
    - user_dim: Dimension of user embedding (default: 32)

    Returns:
    - Dictionary with movie and user embeddings
    """
    print(f"\nCreating MLP embeddings: {movie_dim}-D movie & {user_dim}-D user vectors")

    class Autoencoder(nn.Module):
        def __init__(self, input_dim, embedding_dim):
            super(Autoencoder, self).__init__()
            # Encoder layers
            self.encoder = nn.Sequential(
                nn.Linear(input_dim, input_dim // 2),
                nn.ReLU(),
                nn.Linear(input_dim // 2, embedding_dim),
                nn.ReLU()
            )
            # Decoder layers
            self.decoder = nn.Sequential(
                nn.Linear(embedding_dim, input_dim // 2),
                nn.ReLU(),
                nn.Linear(input_dim // 2, input_dim),
                nn.Sigmoid()  # Sigmoid for the output (fits 0-1 range after normalization)
            )

        def forward(self, x):
            # Get embedding
            embedding = self.encoder(x)
            # Reconstruct
            x_reconstructed = self.decoder(embedding)
            return embedding, x_reconstructed

    # Function to train an autoencoder
    def train_autoencoder(features_df, id_col, embedding_dim, model_name, epochs=50, batch_size=64):
        # Remove ID column and get only feature columns
        features = features_df.drop(columns=[id_col])

        # Normalize features to 0-1 range
        scaler = MinMaxScaler()
        features_scaled = scaler.fit_transform(features)

        # Convert to PyTorch tensors
        features_tensor = torch.FloatTensor(features_scaled)
        dataset = TensorDataset(features_tensor, features_tensor)  # Input = Target for autoencoder
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        # Initialize the model
        input_dim = features.shape[1]
        model = Autoencoder(input_dim, embedding_dim)

        # Check if GPU is available
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        # Loss function and optimizer
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=1e-3)

        # Training loop
        print(f"Training {model_name} autoencoder ({input_dim} → {embedding_dim})")
        for epoch in tqdm(range(epochs), desc=f"Training {model_name} embedding"):
            total_loss = 0
            for batch_x, _ in dataloader:
                batch_x = batch_x.to(device)

                # Forward pass
                _, reconstructed = model(batch_x)

                # Compute loss
                loss = criterion(reconstructed, batch_x)

                # Backward pass and optimize
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                total_loss += loss.item()

            avg_loss = total_loss / len(dataloader)
            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}")

        # Get embeddings for all items
        model.eval()
        with torch.no_grad():
            embeddings, _ = model(features_tensor.to(device))
            embeddings = embeddings.cpu().numpy()

        # Create DataFrame with embeddings
        embedding_df = pd.DataFrame(
            embeddings,
            columns=[f"{model_name}_embed_{i}" for i in range(embedding_dim)]
        )
        embedding_df[id_col] = features_df[id_col].values

        return embedding_df

    # Process movie embeddings
    if not movie_features_df.empty:
        movie_id_col = 'movieId' if 'movieId' in movie_features_df.columns else movie_features_df.columns[0]
        movie_embeddings = train_autoencoder(movie_features_df, movie_id_col, movie_dim, 'movie')
    else:
        print("No movie features available for embedding")
        movie_embeddings = None

    # Process user embeddings
    if user_features_df is not None and not user_features_df.empty:
        user_id_col = 'userId' if 'userId' in user_features_df.columns else user_features_df.columns[0]
        user_embeddings = train_autoencoder(user_features_df, user_id_col, user_dim, 'user')
    else:
        print("No user features available for embedding")
        user_embeddings = None

    return {
        'movie_embeddings': movie_embeddings,
        'user_embeddings': user_embeddings
    }

def normalize_dataframe(df, exclude_cols=None):
    """Normalize all numerical columns in a dataframe to 0-1 range"""
    if exclude_cols is None:
        exclude_cols = []

    df_normalized = df.copy()

    for col in df.columns:
        if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col]):
            # Skip columns with only 0-1 values (already normalized or binary)
            if df[col].nunique() > 2:
                min_val = df[col].min()
                max_val = df[col].max()

                # Only normalize if there's a range
                if max_val > min_val:
                    df_normalized[col] = (df[col] - min_val) / (max_val - min_val)

    return df_normalized

def process_ml_dataset():
    """Main function to process the MovieLens dataset with IMDb/TMDB enrichment"""

    # Load data
    data = load_and_merge_data()
    movies_df = data['movies']
    ratings_df = data['ratings']
    tags_df = data['tags']
    user_df = data['users']

    if movies_df.empty:
        print("Error: No movie data available")
        return None

    # Process movie features
    movie_features = process_movie_features(movies_df, ratings_df, tags_df)

    # Process user features
    user_features = process_user_features(user_df, ratings_df)

    # Normalize features (important before creating embeddings)
    movie_id_col = 'movieId' if 'movieId' in movie_features.columns else movie_features.columns[0]
    movie_features_normalized = normalize_dataframe(movie_features, exclude_cols=[movie_id_col])

    if user_features is not None:
        user_id_col = 'userId' if 'userId' in user_features.columns else user_features.columns[0]
        user_features_normalized = normalize_dataframe(user_features, exclude_cols=[user_id_col])
    else:
        user_features_normalized = None

    # Create MLP embeddings (128-D movie, 32-D user)
    embeddings = create_mlp_embeddings(movie_features_normalized, user_features_normalized)

    # Save results
    output_dir = os.path.join(DATA_DIR, 'processed')
    os.makedirs(output_dir, exist_ok=True)

    # Save processed features
    movie_features.to_csv(os.path.join(output_dir, 'movie_features.csv'), index=False)
    if user_features is not None:
        user_features.to_csv(os.path.join(output_dir, 'user_features.csv'), index=False)

    # Save embeddings
    if embeddings['movie_embeddings'] is not None:
        embeddings['movie_embeddings'].to_csv(os.path.join(output_dir, 'movie_embeddings.csv'), index=False)

    if embeddings['user_embeddings'] is not None:
        embeddings['user_embeddings'].to_csv(os.path.join(output_dir, 'user_embeddings.csv'), index=False)

    print(f"\nAll processed data saved to {output_dir}")

    # Return the results
    return {
        'movie_features': movie_features,
        'user_features': user_features,
        'movie_embeddings': embeddings['movie_embeddings'],
        'user_embeddings': embeddings['user_embeddings']
    }

if __name__ == "__main__":
    # Check for GPU
    if torch.cuda.is_available():
        print(f"GPU is available: {torch.cuda.get_device_name(0)}")
    else:
        print("GPU not available, using CPU")

    # Process the dataset
    results = process_ml_dataset()

    if results:
        print("\n=== Processing Summary ===")
        print(f"Movie features: {results['movie_features'].shape[1]} columns for {len(results['movie_features'])} movies")

        if results['user_features'] is not None:
            print(f"User features: {results['user_features'].shape[1]} columns for {len(results['user_features'])} users")

        if results['movie_embeddings'] is not None:
            movie_embed_cols = [col for col in results['movie_embeddings'].columns if 'embed' in col]
            print(f"Movie embeddings: {len(movie_embed_cols)}-D for {len(results['movie_embeddings'])} movies")

            # Show sample of first 5 dimensions
            sample_cols = [col for col in results['movie_embeddings'].columns if not 'embed' in col] + movie_embed_cols[:5]
            print("\nSample movie embeddings (first 5 dimensions):")
            print(results['movie_embeddings'][sample_cols].head())

        if results['user_embeddings'] is not None:
            user_embed_cols = [col for col in results['user_embeddings'].columns if 'embed' in col]
            print(f"User embeddings: {len(user_embed_cols)}-D for {len(results['user_embeddings'])} users")

            # Show sample of first 5 dimensions
            sample_cols = [col for col in results['user_embeddings'].columns if not 'embed' in col] + user_embed_cols[:5]
            print("\nSample user embeddings (first 5 dimensions):")
            print(results['user_embeddings'][sample_cols].head())

import os
import torch
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from transformers import ViTFeatureExtractor, ViTModel
from torch import nn
import warnings
import glob

class VisualFeatureExtractor:
    """
    Extract and aggregate visual features from movie still images using ViT
    Inputs: 5 representative still-frames + 1 official poster
    Encoder: ViT → 768-D embeddings per image
    Aggregation: Transformer self-attention aggregator → single 768-D visual vector
    """
    def __init__(self, model_name="google/vit-base-patch16-224"):
        """Initialize the ViT feature extractor and model"""
        print(f"Initializing ViT feature extractor using {model_name}...")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {self.device}")

        self.feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)
        self.model = ViTModel.from_pretrained(model_name).to(self.device)
        self.model.eval()

        # Self-attention aggregator
        self.aggregator = SelfAttentionAggregator(embedding_dim=768).to(self.device)

    def extract_image_features(self, image_path):
        """Extract 768-D features from a single image using ViT"""
        try:
            image = Image.open(image_path).convert('RGB')
            inputs = self.feature_extractor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            with torch.no_grad():
                outputs = self.model(**inputs)
                # Get the [CLS] token embedding which represents the entire image
                features = outputs.last_hidden_state[:, 0, :].cpu().numpy()

            return features.flatten()
        except Exception as e:
            print(f"Error extracting features from {image_path}: {e}")
            return np.zeros(768)  # Return zeros if there's an error

    def extract_and_aggregate_features(self, image_paths):
        """
        Extract features from multiple images and aggregate them using self-attention

        Args:
            image_paths: List of paths to movie still images and poster

        Returns:
            768-D aggregated feature vector
        """
        if not image_paths:
            print("No images provided for feature extraction")
            return np.zeros(768)

        # Extract features from each image
        individual_features = []
        for path in image_paths:
            if os.path.exists(path):
                features = self.extract_image_features(path)
                individual_features.append(features)
            else:
                print(f"Warning: Image not found: {path}")

        if not individual_features:
            print("No valid images found for feature extraction")
            return np.zeros(768)

        # Convert to tensor for aggregation
        features_tensor = torch.tensor(np.array(individual_features), dtype=torch.float32).to(self.device)

        # Apply self-attention aggregation
        with torch.no_grad():
            aggregated_features = self.aggregator(features_tensor).cpu().numpy()

        return aggregated_features.flatten()

class SelfAttentionAggregator(nn.Module):
    """
    Self-attention mechanism to aggregate multiple image embeddings into a single vector
    """
    def __init__(self, embedding_dim=768, num_heads=8):
        super(SelfAttentionAggregator, self).__init__()
        self.embedding_dim = embedding_dim

        # Multi-head self-attention
        self.self_attention = nn.MultiheadAttention(
            embed_dim=embedding_dim,
            num_heads=num_heads,
            batch_first=True
        )

        # Feed-forward network for final projection
        self.ffn = nn.Sequential(
            nn.Linear(embedding_dim, embedding_dim),
            nn.GELU(),
            nn.Linear(embedding_dim, embedding_dim)
        )

        # Layer normalization
        self.norm1 = nn.LayerNorm(embedding_dim)
        self.norm2 = nn.LayerNorm(embedding_dim)

    def forward(self, x):
        """
        Args:
            x: Tensor of shape [num_images, embedding_dim]
               where num_images is the number of still frames + poster

        Returns:
            Tensor of shape [1, embedding_dim] representing the aggregated visual features
        """
        # Self-attention with residual connection
        attn_output, _ = self.self_attention(x, x, x)
        x = x + attn_output
        x = self.norm1(x)

        # Feed-forward with residual
        ffn_output = self.ffn(x)
        x = x + ffn_output
        x = self.norm2(x)

        # Average pooling to get a single vector
        return torch.mean(x, dim=0, keepdim=True)

def process_movie_visual_features(movie_stills_dir, output_file='movie_visual_features.csv'):
    """
    Process all movies in the representative_stills directory and extract ViT features

    Args:
        movie_stills_dir: Directory containing subdirectories with movie stills
        output_file: CSV file to save the extracted features
    """
    print(f"Processing visual features for movies in {movie_stills_dir}...")

    # Initialize the feature extractor
    extractor = VisualFeatureExtractor()

    # Get a list of all movie directories
    movie_dirs = [d for d in glob.glob(os.path.join(movie_stills_dir, "*")) if os.path.isdir(d)]
    print(f"Found {len(movie_dirs)} movie directories")

    # Results to store movie IDs and their visual features
    results = []

    for movie_dir in tqdm(movie_dirs, desc="Processing movies"):
        try:
            # Extract movie ID from directory name
            movie_id = os.path.basename(movie_dir).split('_')[-1]  # Assumes format like "01_tt0111161"
            if not movie_id.startswith('tt'):
                movie_id = 'tt' + movie_id

            # Find all image files in the directory
            image_files = glob.glob(os.path.join(movie_dir, "*.jpg"))

            # Check if IMDB poster exists
            imdb_poster = next((f for f in image_files if 'imdb_poster' in f.lower()), None)
            if not imdb_poster:
                warnings.warn(f"No IMDb poster found for {movie_id}. Consider downloading with the digestion tool.")

            # Check for representative stills
            rep_stills = [f for f in image_files if 'representative' in f.lower() or 'backdrop' in f.lower()]

            # Combine poster and stills, with poster first if available
            all_images = []
            if imdb_poster:
                all_images.append(imdb_poster)
            all_images.extend(rep_stills)

            # Limit to 6 images (1 poster + 5 stills) if we have more
            all_images = all_images[:6]

            if len(all_images) == 0:
                print(f"Warning: No images found for {movie_id}")
                continue

            print(f"Processing {len(all_images)} images for movie {movie_id}")

            # Extract and aggregate features
            visual_features = extractor.extract_and_aggregate_features(all_images)

            # Store results
            feature_dict = {'movie_id': movie_id}
            for i, feat in enumerate(visual_features):
                feature_dict[f'vit_feature_{i+1}'] = feat

            results.append(feature_dict)

        except Exception as e:
            print(f"Error processing {movie_dir}: {e}")

    # Convert results to DataFrame and save
    if results:
        df = pd.DataFrame(results)
        df.to_csv(output_file, index=False)
        print(f"Saved visual features for {len(df)} movies to {output_file}")
        return df
    else:
        print("No features were extracted")
        return None

def check_missing_posters(data_dir):
    """Check for movies that are missing IMDb posters"""
    movie_dirs = [d for d in glob.glob(os.path.join(data_dir, "*")) if os.path.isdir(d)]

    missing_posters = []
    for movie_dir in movie_dirs:
        movie_id = os.path.basename(movie_dir).split('_')[-1]
        imdb_poster = os.path.join(movie_dir, "imdb_poster.jpg")

        if not os.path.exists(imdb_poster):
            missing_posters.append(movie_id)

    print(f"Found {len(missing_posters)} movies without IMDb posters")
    return missing_posters

if __name__ == "__main__":
    # Directory containing representative stills for each movie
    REPRESENTATIVE_STILLS_DIR = "representative_stills"

    # Check if we have any missing posters
    missing = check_missing_posters(REPRESENTATIVE_STILLS_DIR)
    if missing:
        print("The following movies are missing IMDb posters:")
        for movie_id in missing[:10]:  # Show first 10
            print(f"  - {movie_id}")
        if len(missing) > 10:
            print(f"  ... and {len(missing) - 10} more")

        print("\nConsider downloading posters using the IMDb digestion tool")

    # Process all movies to extract visual features
    visual_features_df = process_movie_visual_features(REPRESENTATIVE_STILLS_DIR)

    # Display sample of the results
    if visual_features_df is not None:
        print("\nSample of extracted visual features:")
        print(visual_features_df.iloc[:3, :10])  # Show first 3 rows, first 10 columns