# -*- coding: utf-8 -*-
"""resnet_select.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1afQ6FcowCgarTuhDGI5ZbvhoJG5ge5C1
"""

!pip install cinemagoer
!pip install selenium
!pip install undetected_chromedriver
!pip install serpapi

import os
import torch
import numpy as np
import torchvision.transforms as transforms
from torchvision import models
from sklearn.cluster import KMeans
from PIL import Image
import requests
from google.colab import userdata

SERPAPI_API_KEY = userdata.get('SERPAPI_API_KEY')

# Function to download an image from URL
def download_image(url, save_path):
    """Download an image from url to save_path."""
    try:
        response = requests.get(url, stream=True, timeout=10)
        response.raise_for_status()
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except Exception as e:
        print(f"Error downloading {url}: {e}")
        return False

# SerpAPI image download function
try:
    # Try the updated API (newer versions)
    import serpapi

    def download_serpapi_images(query, dest_folder, max_images=5):
        """Use SerpAPI to fetch up to max_images stills for `query`."""
        os.makedirs(dest_folder, exist_ok=True)
        params = {
            "engine": "google_images",
            "q": query,
            "api_key": SERPAPI_API_KEY,
            "num": max_images,
        }
        results = serpapi.search(params)
        images = results.get("images_results", [])[:max_images]
        for idx, img in enumerate(images, start=1):
            url = img.get("original") or img.get("thumbnail")
            if not url:
                continue
            fname = os.path.join(dest_folder, f"serpapi_{idx}.jpg")
            download_image(url, fname)

except (ImportError, AttributeError):
    # Try the classic API (older versions)
    # First make sure we have the correct package
    try:
        from serpapi import GoogleSearch
    except ImportError:
        # Install the correct package if it's not available
        !pip install google-search-results
        from serpapi import GoogleSearch

    def download_serpapi_images(query, dest_folder, max_images=5):
        """Use SerpAPI to fetch up to max_images stills for `query`."""
        os.makedirs(dest_folder, exist_ok=True)
        params = {
            "engine": "google_images",
            "q": query,
            "api_key": SERPAPI_API_KEY,
            "num": max_images,
        }
        search = GoogleSearch(params)
        results = search.get_dict()
        images = results.get("images_results", [])[:max_images]
        for idx, img in enumerate(images, start=1):
            url = img.get("original") or img.get("thumbnail")
            if not url:
                continue
            fname = os.path.join(dest_folder, f"serpapi_{idx}.jpg")
            download_image(url, fname)

def select_representative_images(image_paths, top_n=5, device="cpu"):
    """Extract CNN features for each path and pick top_n diverse/representative images by K-means."""
    # 1) load a pretrained ResNet50 up to penultimate layer
    model = models.resnet50(pretrained=True)
    model = torch.nn.Sequential(*list(model.children())[:-1]).to(device).eval()

    # 2) preprocessing
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    feats = []
    valid_paths = []
    for p in image_paths:
        try:
            img = Image.open(p).convert("RGB")
            tensor = preprocess(img).unsqueeze(0).to(device)
            with torch.no_grad():
                out = model(tensor)      # shape (1, 2048, 1, 1)
            vec = out.squeeze().cpu().numpy()  # (2048,)
            feats.append(vec)
            valid_paths.append(p)
        except Exception as e:
            print(f"  - failed to extract feat from {p}: {e}")

    if len(feats) <= top_n:
        return valid_paths

    # 3) K-means cluster into top_n clusters, pick closest-to-centroid per cluster
    X = np.stack(feats, axis=0)
    km = KMeans(n_clusters=top_n, random_state=0).fit(X)
    centers = km.cluster_centers_
    labels = km.labels_

    selected = []
    for i in range(top_n):
        idxs = np.where(labels == i)[0]
        # distances to centroid
        dists = np.linalg.norm(X[idxs] - centers[i], axis=1)
        best = idxs[np.argmin(dists)]
        selected.append(valid_paths[best])

    return selected

# --- EXAMPLE USAGE INSIDE process_movie_by_id() ---
def process_movie_by_id(movie_id, rank, imdb_features):
    """Process a movie by its ID, download images, and select representative ones."""
    # Create a directory for the movie
    movie_dir = f"movie_{movie_id}"
    os.makedirs(movie_dir, exist_ok=True)

    # 1) Download SerpAPI stills
    serpapi_folder = os.path.join(movie_dir, "serpapi")
    download_serpapi_images(f"{imdb_features['Title']} movie stills", serpapi_folder, max_images=5)

    # 2) Gather all downloaded image paths
    all_imgs = []
    for fname in os.listdir(movie_dir):
        if fname.lower().endswith(".jpg"):
            all_imgs.append(os.path.join(movie_dir, fname))

    # Also include serpapi subfolder
    if os.path.exists(serpapi_folder):
        for fname in os.listdir(serpapi_folder):
            if fname.lower().endswith(".jpg"):
                all_imgs.append(os.path.join(serpapi_folder, fname))

    # 3) Pick the 5 most representative images
    selected = select_representative_images(all_imgs, top_n=5)
    print(f"Selected representative images:\n  " + "\n  ".join(selected))

    # Return the selected images or do further processing
    return selected

# Example of how to set up the API key in Colab (run this once)
# You'll be prompted to input your key which will be securely stored
# This is a commented example - uncomment and run separately if needed
"""
from google.colab import userdata

# This will open a dialog to input your API key
# The key will be stored securely and won't appear in your notebook
# Access it with userdata.get('SERPAPI_API_KEY')
userdata.set('SERPAPI_API_KEY', 'your-key-here')
"""

# Example usage:
if __name__ == "__main__":
    # This is a dummy example - replace with your actual code
    movie_info = {"Title": "The Godfather"}
    selected_images = process_movie_by_id("tt0068646", 1, movie_info)
    print(f"Final selected images: {selected_images}")

import os
import requests
import time
import json
import traceback
from PIL import Image
from io import BytesIO
from tqdm import tqdm
from google.colab import userdata

# Install necessary packages
try:
    from serpapi import GoogleSearch
except ImportError:
    !pip install google-search-results
    from serpapi import GoogleSearch

try:
    from imdb import Cinemagoer
except ImportError:
    !pip install cinemagoer
    from imdb import Cinemagoer

# Securely get API keys from Colab
SERPAPI_API_KEY = userdata.get('SERPAPI_API_KEY')
TMDB_API_KEY = userdata.get('TMDB_API_KEY')

# IMDb top 10 movies list with their IMDb IDs
TOP_10_IMDB_IDS = [
    "0111161",  # 1. The Shawshank Redemption
    "0068646",  # 2. The Godfather
    "0071562",  # 3. The Godfather: Part II
    "0468569",  # 4. The Dark Knight
    "0050083",  # 5. 12 Angry Men
    "0108052",  # 6. Schindler's List
    "0167260",  # 7. The Lord of the Rings: The Return of the King
    "0110912",  # 8. Pulp Fiction
    "0060196",  # 9. The Good, the Bad and the Ugly
    "0120737",  # 10. The Lord of the Rings: The Fellowship of the Ring

        "0137523",  # 11. Fight Club
    "0109830",  # 12. Forrest Gump
    "1375666",  # 13. Inception
    "0080684",  # 14. Star Wars: Episode V - The Empire Strikes Back
    "0167261",  # 15. The Lord of the Rings: The Two Towers
    "0073486",  # 16. One Flew Over the Cuckoo's Nest
    "0099685",  # 17. Goodfellas
    "0133093",  # 18. The Matrix
    "0047478",  # 19. Seven Samurai
    "0114369",  # 20. Se7en
    "0317248",  # 21. City of God
    "0076759",  # 22. Star Wars: Episode IV - A New Hope
    "0102926",  # 23. The Silence of the Lambs
    "0038650",  # 24. It's a Wonderful Life
    "0118799",  # 25. Life Is Beautiful

    # 26-50
    "0120815",  # 26. Saving Private Ryan
    "0816692",  # 27. Interstellar
    "0120689",  # 28. The Green Mile
    "0103064",  # 29. Terminator 2: Judgment Day
    "0088763",  # 30. Back to the Future
    "0245429",  # 31. Spirited Away
    "0054215",  # 32. Psycho
    "0110357",  # 33. The Lion King
    "0110413",  # 34. Léon: The Professional
    "0172495",  # 35. Gladiator
    "0407887",  # 36. The Departed
    "0482571",  # 37. The Prestige
    "0253474",  # 38. The Pianist
    "2582802",  # 39. Whiplash
    "0095327",  # 40. Grave of the Fireflies
    "0095765",  # 41. Cinema Paradiso
    "0047396",  # 42. Rear Window
    "0078748",  # 43. Alien
    "0078788",  # 44. Apocalypse Now
    "0209144",  # 45. Memento
    "0082971",  # 46. Raiders of the Lost Ark
    "0032553",  # 47. The Great Dictator
    "1853728",  # 48. Django Unchained
    "0405094",  # 49. The Lives of Others
    "0043014",  # 50. Sunset Boulevard

    # 51-100
    "0027977",  # 51. Modern Times
    "0910970",  # 52. WALL·E
    "0081505",  # 53. The Shining
    "0043014",  # 54. Sunset Blvd.
    "0057012",  # 55. Dr. Strangelove
    "0052357",  # 56. Vertigo
    "0034583",  # 57. Casablanca
    "0169547",  # 58. American Beauty
    "0090605",  # 59. Aliens
    "0033467",  # 60. Citizen Kane
    "0087843",  # 61. Once Upon a Time in America
    "0082096",  # 62. Das Boot
    "0112573",  # 63. Braveheart
    "0056172",  # 64. Lawrence of Arabia
    "1745960",  # 65. Top Gun: Maverick
    "0180093",  # 66. Requiem for a Dream
    "0022100",  # 67. M
    "0986264",  # 68. Taare Zameen Par
    "0338013",  # 69. Eternal Sunshine of the Spotless Mind
    "8579674",  # 70. 1917
    "0119698",  # 71. Princess Mononoke
    "0086190",  # 72. Star Wars: Episode VI - Return of the Jedi
    "8267604",  # 73. Capernaum
    "0062622",  # 74. 2001: A Space Odyssey
    "0361748",  # 75. Inglourious Basterds
    "0059578",  # 76. The Good, the Bad and the Ugly
    "0052311",  # 77. 12 Angry Men (TV)
    "0053125",  # 78. North by Northwest
    "0066921",  # 79. A Clockwork Orange
    "0093058",  # 80. Full Metal Jacket
    "0036775",  # 81. Double Indemnity
    "0075314",  # 82. Taxi Driver
    "0045152",  # 83. Singin' in the Rain
    "0070735",  # 84. The Sting
    "0056592",  # 85. To Kill a Mockingbird
    "0040522",  # 86. Bicycle Thieves
    "0208092",  # 87. Snatch
    "0086879",  # 88. Amadeus
    "0211915",  # 89. Amélie
    "0114709",  # 90. Toy Story
    "0056217",  # 91. The Great Escape
    "0435761",  # 92. Toy Story 3
    "0110413",  # 93. Léon: The Professional
    "0119217",  # 94. Good Will Hunting
    "0110357",  # 95. The Lion King
    "0097165",  # 96. Dead Poets Society
    "0113277",  # 97. Heat
    "0064116",  # 98. Once Upon a Time in the West
    "0047296",  # 99. On the Waterfront
    "0105236",  # 100. Reservoir Dogs

    "0120586",  # 101. American History X
    "0103064",  # 102. Terminator 2: Judgment Day
    "0095765",  # 103. Cinema Paradiso
    "0367110",  # 104. Oldboy
    "0042876",  # 105. Rashomon
    "1305806",  # 106. The Secret in Their Eyes
    "0372784",  # 107. Batman Begins
    "0469494",  # 108. There Will Be Blood
    "0055630",  # 109. Yojimbo
    "0040897",  # 110. The Treasure of the Sierra Madre
    "0012349",  # 111. The Kid
    "0114814",  # 112. The Usual Suspects
    "0053291",  # 113. Some Like It Hot
    "0457430",  # 114. Pan's Labyrinth
    "0363163",  # 115. Downfall
    "0089881",  # 116. Come and See
    "0042192",  # 117. All About Eve
    "1392214",  # 118. Prisoners
    "0044741",  # 119. Ikiru
    "0117951",  # 120. Trainspotting
    "0057115",  # 121. The Great Escape
    "0071315",  # 122. Chinatown
    "0057565",  # 123. High and Low
    "0118715",  # 124. The Big Lebowski
    "1832382",  # 125. A Separation
    "0354407",  # 126. The Pianist
    "1049413",  # 127. Up
    "0095016",  # 128. Die Hard
    "0015864",  # 129. The Gold Rush
    "0119488",  # 130. L.A. Confidential
    "0017925",  # 131. The General
    "0050976",  # 132. The Seventh Seal
    "0050986",  # 133. Wild Strawberries
    "1877830",  # 134. X-Men: Days of Future Past
    "0347149",  # 135. Howl's Moving Castle
    "0080678",  # 136. The Elephant Man
    "0116282",  # 137. Fargo
    "0096283",  # 138. My Neighbor Totoro
    "0055031",  # 139. Judgment at Nuremberg
    "0268978",  # 140. A Beautiful Mind
    "0266543",  # 141. Finding Nemo
    "1205489",  # 142. Gran Torino
    "0477348",  # 143. No Country for Old Men
    "0118849",  # 144. Children of Heaven
    "0266697",  # 145. Kill Bill: Vol. 1
    "0091763",  # 146. Platoon
    "0084787",  # 147. The Thing
    "0046912",  # 148. Dial M for Murder
    "1130884",  # 149. Shutter Island
    "0074896",  # 150. The Message

    "0029583",  # 151. Snow White and the Seven Dwarfs
    "0032976",  # 152. Rebecca
    "0031679",  # 153. Mr. Smith Goes to Washington
    "0079944",  # 154. Stalker
    "0107290",  # 155. Jurassic Park
    "0046268",  # 156. The Wages of Fear
    "0053198",  # 157. Ben-Hur
    "0120735",  # 158. Lock, Stock and Two Smoking Barrels
    "0245429",  # 159. Spirited Away
    "0059742",  # 160. The Sound of Music
    "0061512",  # 161. Cool Hand Luke
    "0116231",  # 162. The Bandit
    "0051201",  # 163. Witness for the Prosecution
    "0978762",  # 164. Mary and Max
    "0083658",  # 165. Blade Runner
    "1895587",  # 166. Spotlight
    "0017136",  # 167. Metropolis
    "0347149",  # 168. Howl's Moving Castle
    "0050212",  # 169. Paths of Glory
    "0116282",  # 170. Fargo
    "0088247",  # 171. The Terminator
    "0015324",  # 172. Sherlock Jr.
    "0050825",  # 173. Nights of Cabiria
    "0198781",  # 174. Monsters, Inc.
    "1979320",  # 175. Rush
    "0112641",  # 176. Casino
    "0077416",  # 177. The Deer Hunter
    "0892769",  # 178. How to Train Your Dragon
    "0167404",  # 179. The Sixth Sense
    "0041959",  # 180. The Third Man
    "0046911",  # 181. Rear Window
    "1454029",  # 182. The Help
    "0015324",  # 183. Sherlock Jr.
    "0031381",  # 184. Gone with the Wind
    "0097576",  # 185. Indiana Jones and the Last Crusade
    "0080684",  # 186. Star Wars: Episode V - The Empire Strikes Back
    "0993846",  # 187. The Wolf of Wall Street
    "0050613",  # 188. The Bridge on the River Kwai
    "0092005",  # 189. Stand by Me
    "0111161",  # 190. The Shawshank Redemption
    "0758758",  # 191. Into the Wild
    "0060107",  # 192. Andrei Rublev
    "0107207",  # 193. In the Name of the Father
    "0046438",  # 194. Tokyo Story
    "0056801",  # 195. 8½
    "0113247",  # 196. La Haine
    "4430212",  # 197. Drishyam
    "0055630",  # 198. Yojimbo
    "0089881",  # 199. Come and See
    "0075148",  # 200. Rocky

    "0052618",  # 201. Ben-Hur
    "0405159",  # 202. Million Dollar Baby
    "0032551",  # 203. The Grapes of Wrath
    "0079470",  # 204. Monty Python's Life of Brian
    "0046250",  # 205. Roman Holiday
    "0048473",  # 206. Rififi
    "0071411",  # 207. Dersu Uzala
    "0036868",  # 208. The Best Years of Our Lives
    "0053291",  # 209. Some Like It Hot
    "2278388",  # 210. The Grand Budapest Hotel
    "0015864",  # 211. The Gold Rush
    "0382932",  # 212. Ratatouille
    "0246578",  # 213. Donnie Darko
    "0056801",  # 214. 8½
    "0440963",  # 215. The Bourne Ultimatum
    "0118694",  # 216. In the Mood for Love
    "0119217",  # 217. Good Will Hunting
    "0105695",  # 218. Unforgiven
    "0942385",  # 219. Tropic Thunder
    "0796366",  # 220. Star Trek
    "0075148",  # 221. Rocky
    "0401792",  # 222. Sin City
    "0112471",  # 223. Before Sunrise
    "0032138",  # 224. The Wizard of Oz
    "0542337",  # 225. Million Dollar Baby
    "0053198",  # 226. Ben-Hur
    "0044079",  # 227. Strangers on a Train
    "0070511",  # 228. Papillon
    "0070047",  # 229. The Exorcist
    "0087544",  # 230. Nausicaä of the Valley of the Wind
    "0012349",  # 231. The Kid
    "0062136",  # 232. The Graduate
    "0353969",  # 233. Memories of Murder
    "0019254",  # 234. The Passion of Joan of Arc
    "0325980",  # 235. Pirates of the Caribbean: The Curse of the Black Pearl
    "0097223",  # 236. Grave of the Fireflies
    "0061184",  # 237. Who's Afraid of Virginia Woolf?
    "0107048",  # 238. Groundhog Day
    "0059742",  # 239. The Sound of Music
    "0046912",  # 240. Dial M for Murder
    "0031679",  # 241. Mr. Smith Goes to Washington
    "0021749",  # 242. City Lights
    "5074352",  # 243. Dangal
    "0019254",  # 244. The Passion of Joan of Arc
    "0033870",  # 245. The Magnificent Ambersons
    "5027774",  # 246. Three Billboards Outside Ebbing, Missouri
    "0050212",  # 247. Paths of Glory
    "0017925",  # 248. The General
    "4016934",  # 249. The Handmaiden
    "0052311",  # 250. Twelve Angry Men
]

print("Initializing Cinemagoer...")
ia = Cinemagoer()

def clean_filename(name):
    """Clean filename to remove invalid characters"""
    invalid = '<>:"/\\|?*'
    for c in invalid:
        name = name.replace(c, '_')
    return name

def download_image(url, save_path, headers=None):
    """Download an image from URL to save_path"""
    if os.path.exists(save_path):
        print(f"  - Image already exists: {save_path}")
        return True

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()

        with open(save_path, 'wb') as f:
            f.write(response.content)

        # Optionally optimize the image
        try:
            img = Image.open(BytesIO(response.content))
            if img.mode != 'RGB':
                img = img.convert('RGB')

            # Resize if too large
            max_dim = 1200
            w, h = img.size
            if w > max_dim or h > max_dim:
                if w > h:
                    new_w = max_dim
                    new_h = int(h * (max_dim / w))
                else:
                    new_h = max_dim
                    new_w = int(w * (max_dim / h))
                img = img.resize((new_w, new_h), Image.LANCZOS)

            img.save(save_path, 'JPEG', quality=95, optimize=True)
        except Exception as e:
            print(f"  - Error optimizing image: {e}")

        print(f"  - Downloaded: {save_path}")
        return True

    except Exception as e:
        print(f"  - Failed to download {url}: {e}")
        return False

def download_serpapi_images(query, dest_folder, max_images=5):
    """Use SerpAPI to fetch movie stills"""
    os.makedirs(dest_folder, exist_ok=True)

    params = {
        "engine": "google_images",
        "q": query,
        "api_key": SERPAPI_API_KEY,
        "num": max_images * 2,  # Get more to ensure we have enough valid ones
    }

    print(f"Searching for images: '{query}'")
    search = GoogleSearch(params)
    results = search.get_dict()
    images = results.get("images_results", [])

    successful_downloads = 0
    for i, img in enumerate(images):
        if successful_downloads >= max_images:
            break

        url = img.get("original") or img.get("thumbnail")
        if not url:
            continue

        file_path = os.path.join(dest_folder, f"backdrop_serpapi_{successful_downloads+1}.jpg")

        if download_image(url, file_path):
            successful_downloads += 1

        # Avoid rate limiting
        time.sleep(0.5)

    print(f"Downloaded {successful_downloads} images from SerpAPI")
    return successful_downloads

def get_imdb_movie_details(imdb_id):
    """Get movie details from IMDb using Cinemagoer"""
    if not imdb_id.startswith('tt'):
        imdb_id = f"tt{imdb_id}"

    print(f"Fetching IMDb details for {imdb_id}...")
    try:
        movie = ia.get_movie(imdb_id[2:])  # Remove 'tt' prefix for Cinemagoer
        return movie
    except Exception as e:
        print(f"Error fetching IMDb details: {e}")
        return None

def extract_imdb_features(movie, rank):
    """Extract key features from IMDb movie object"""
    if not movie:
        return {}

    features = {
        "Rank": rank,
        "Title": movie.get('title', ''),
        "Year": movie.get('year', ''),
        "IMDb_ID": movie.get('imdbID', ''),
        "Rating": movie.get('rating', ''),
        "Genres": '|'.join(movie.get('genres', [])),
        "Directors": '|'.join([d.get('name', '') for d in movie.get('directors', []) if 'name' in d]),
        "Cast": '|'.join([a.get('name', '') for a in movie.get('cast', [])[:5] if 'name' in a]),
        "Plot": movie.get('plot outline', '')
    }
    features["Poster_URL"] = movie.get('full-size cover url', movie.get('cover url', ''))
    return features

def find_tmdb_id_by_imdb_id(imdb_id):
    """Find TMDB ID from IMDb ID"""
    if not imdb_id.startswith('tt'):
        imdb_id = f"tt{imdb_id}"

    url = f"https://api.themoviedb.org/3/find/{imdb_id}"
    params = {"api_key": TMDB_API_KEY, "external_source": "imdb_id"}

    try:
        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            if data["movie_results"]:
                return data["movie_results"][0]["id"]
            print(f"No TMDB movie found for IMDb ID {imdb_id}")
        else:
            print(f"TMDB API request failed: {response.status_code}")
    except Exception as e:
        print(f"Error finding TMDB ID: {e}")

    return None

def get_tmdb_movie_images(tmdb_id):
    """Get backdrops from TMDB"""
    url = f"https://api.themoviedb.org/3/movie/{tmdb_id}/images"
    params = {"api_key": TMDB_API_KEY}

    try:
        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            return data.get("backdrops", [])
        else:
            print(f"Failed to get TMDB images: {response.status_code}")
    except Exception as e:
        print(f"Error getting TMDB images: {e}")

    return []

def download_tmdb_backdrops(backdrops, movie_dir, max_count=5):
    """Download backdrop images from TMDB"""
    downloaded = 0

    for i, backdrop in enumerate(backdrops[:max_count]):
        file_path = backdrop.get("file_path")
        if not file_path:
            continue

        img_url = f"https://image.tmdb.org/t/p/original{file_path}"
        save_path = os.path.join(movie_dir, f"backdrop_{i+1}.jpg")

        if download_image(img_url, save_path):
            downloaded += 1

        time.sleep(0.2)  # Small delay between downloads

    print(f"Downloaded {downloaded} backdrops from TMDB")
    return downloaded

def download_imdb_poster(poster_url, movie_dir):
    """Download IMDb poster"""
    if not poster_url:
        print("No poster URL provided")
        return False

    save_path = os.path.join(movie_dir, "imdb_poster.jpg")
    return download_image(poster_url, save_path)

def process_movie(imdb_id, rank):
    """Process a single movie by IMDb ID"""
    print(f"\n{'='*50}")
    print(f"Processing #{rank}: IMDb ID tt{imdb_id}")
    print(f"{'='*50}")

    # Create base directory for this movie
    movie_dir = os.path.join("imdb_top_10", f"{rank:02d}_tt{imdb_id}")
    os.makedirs(movie_dir, exist_ok=True)

    # Get IMDb details
    imdb_movie = get_imdb_movie_details(imdb_id)
    if not imdb_movie:
        print(f"Could not retrieve IMDb data for tt{imdb_id}, skipping")
        return False

    movie_title = imdb_movie.get('title', f"Movie_{imdb_id}")
    print(f"Movie: {movie_title} ({imdb_movie.get('year', 'Unknown')})")

    # Extract relevant IMDb features
    imdb_features = extract_imdb_features(imdb_movie, rank)

    # Download IMDb poster
    poster_url = imdb_features.get("Poster_URL")
    if poster_url:
        print("Downloading IMDb poster...")
        download_imdb_poster(poster_url, movie_dir)
    else:
        print("No IMDb poster URL found")

    # Get TMDB ID
    tmdb_id = find_tmdb_id_by_imdb_id(imdb_id)
    if not tmdb_id:
        print(f"Could not find TMDB ID for IMDb ID tt{imdb_id}")
    else:
        print(f"Found TMDB ID: {tmdb_id}")

        # Get and download TMDB backdrops
        backdrops = get_tmdb_movie_images(tmdb_id)
        if backdrops:
            print(f"Found {len(backdrops)} backdrops on TMDB")
            download_tmdb_backdrops(backdrops, movie_dir)
        else:
            print("No TMDB backdrops found")

    # Download stills using SerpAPI
    print("Downloading movie stills using SerpAPI...")
    download_serpapi_images(f"{movie_title} movie stills", movie_dir)

    print(f"Finished processing #{rank}: {movie_title}")
    return True

def main():
    """Process all the top 10 IMDb movies"""
    print("Starting IMDb Top 10 Movies Processing")

    # Ensure base directory exists
    os.makedirs("imdb_top", exist_ok=True)

    # Process each movie
    for rank, imdb_id in enumerate(TOP_10_IMDB_IDS, 1):
        process_movie(imdb_id, rank)
        # Add a delay between movies to avoid API rate limits
        if rank < len(TOP_10_IMDB_IDS):
            print("Waiting before processing next movie...")
            time.sleep(2)

    print("\nAll movies processed!")
    print("Files are saved in the 'imdb_top_10' directory")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"An error occurred: {e}")
        traceback.print_exc()

import os
import numpy as np
import torch
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image
from sklearn.cluster import KMeans
import shutil
from tqdm import tqdm

def select_representative_images(movie_dir, output_dir=None, k_clusters=5, device="cpu"):
    """
    Step 3: Representative Image Selection
    - Cluster all image embeddings with K-means
    - Pick the image closest to each centroid as the "most characteristic"

    Args:
        movie_dir (str): Directory containing all downloaded images for a movie
        output_dir (str, optional): Directory to save selected representative images
        k_clusters (int): Number of clusters to create (default: 5)
        device (str): Device to run feature extraction on ("cpu" or "cuda")

    Returns:
        list: Paths to selected representative images
    """
    print(f"\nSelecting representative images from {movie_dir}...")

    # Find all JPG images in the directory
    image_paths = []
    for filename in os.listdir(movie_dir):
        if filename.lower().endswith('.jpg'):
            image_paths.append(os.path.join(movie_dir, filename))

    if len(image_paths) == 0:
        print(f"No images found in {movie_dir}")
        return []

    print(f"Found {len(image_paths)} images")

    # Load a pretrained ResNet50 (without final FC layer)
    model = models.resnet50(pretrained=True)
    model = torch.nn.Sequential(*list(model.children())[:-1]).to(device).eval()

    # Image preprocessing pipeline (same as Step 2)
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    # Extract features for each image
    features = []
    valid_paths = []

    print("Extracting deep features from images...")
    for img_path in tqdm(image_paths):
        try:
            # Load and preprocess image
            img = Image.open(img_path).convert('RGB')
            img_tensor = preprocess(img).unsqueeze(0).to(device)

            # Extract features
            with torch.no_grad():
                feature = model(img_tensor)

            # Get 2048-D embedding vector
            embedding = feature.squeeze().cpu().numpy()
            features.append(embedding)
            valid_paths.append(img_path)

        except Exception as e:
            print(f"Error processing {img_path}: {e}")

    if len(features) == 0:
        print("No valid features extracted")
        return []

    # If we have fewer images than clusters, adjust k_clusters
    actual_k = min(k_clusters, len(features))
    if actual_k < k_clusters:
        print(f"Warning: Only {actual_k} valid images found, using {actual_k} clusters instead of {k_clusters}")

    # Convert features to numpy array
    X = np.array(features)

    # Perform K-means clustering
    print(f"Performing K-means clustering with k={actual_k}...")
    kmeans = KMeans(n_clusters=actual_k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X)

    # Find images closest to each centroid
    selected_images = []
    centroids = kmeans.cluster_centers_

    for i in range(actual_k):
        # Get indices of images in current cluster
        cluster_indices = np.where(cluster_labels == i)[0]

        if len(cluster_indices) == 0:
            continue

        # Calculate distance from each point in cluster to its centroid
        distances = np.linalg.norm(X[cluster_indices] - centroids[i], axis=1)

        # Find the image closest to the centroid
        closest_idx = cluster_indices[np.argmin(distances)]
        selected_images.append(valid_paths[closest_idx])

        print(f"Cluster {i+1}: Selected {os.path.basename(valid_paths[closest_idx])}")

    # Copy selected images to output directory if provided
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        for i, img_path in enumerate(selected_images):
            dest_path = os.path.join(output_dir, f"representative_{i+1}.jpg")
            shutil.copy(img_path, dest_path)
            print(f"Copied to {dest_path}")

    return selected_images

# Example usage:
def process_all_movies(base_dir="imdb_top", output_base_dir="representative_stills"):
    """
    Process all movie directories to select representative images
    """
    os.makedirs(output_base_dir, exist_ok=True)

    # Find all movie directories
    for movie_dir in os.listdir(base_dir):
        full_movie_path = os.path.join(base_dir, movie_dir)
        if os.path.isdir(full_movie_path):
            # Create output directory for this movie
            movie_output_dir = os.path.join(output_base_dir, movie_dir)
            os.makedirs(movie_output_dir, exist_ok=True)

            # Select representative images
            selected = select_representative_images(
                full_movie_path,
                output_dir=movie_output_dir
            )

            print(f"Selected {len(selected)} representative images for {movie_dir}")
            print("-" * 50)

if __name__ == "__main__":
    # Use GPU if available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    process_all_movies()
    print("Completed representative image selection!")