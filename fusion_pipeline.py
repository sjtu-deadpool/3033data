# -*- coding: utf-8 -*-
"""fusion_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SxvSTHewX_gfMm2YTuEKLQXYAdB-5Tun
"""

import os
import pandas as pd
import numpy as np
from tqdm import tqdm
import torch
import matplotlib.pyplot as plt
import seaborn as sns

class FeatureFusion:
    """
    Movie Feature Fusion Pipeline
    Combines all feature types:
    1. Visual Features (768-D)
    2. Textual Features (2304-D)
    3. Structured Metadata (128-D)
    4. User Features (32-D)
    5. Genome Features (1128-D)

    Final vector: concat(768-D visual, 2304-D textual, 128-D structured, 32-D user, 1128-D genome)
    """

    def __init__(self, data_dir='.'):
        """Initialize the feature fusion module"""
        print("Initializing Feature Fusion module...")
        self.data_dir = data_dir

        # Paths for different feature files
        self.visual_features_path = os.path.join(data_dir, 'visual_features.csv')
        self.textual_features_path = os.path.join(data_dir, 'textual_features.csv')
        self.structured_features_path = os.path.join(data_dir, 'movie_structured_embeddings.csv')
        self.user_features_path = os.path.join(data_dir, 'user_structured_embeddings.csv')
        self.genome_features_path = os.path.join(data_dir, 'genome-scores.csv')

        # Expected feature dimensions
        self.visual_dim = 768
        self.textual_dim = 2304
        self.structured_dim = 128
        self.user_dim = 32
        self.genome_dim = 1128

        # Total fused vector dimension
        self.total_dim = self.visual_dim + self.textual_dim + self.structured_dim + self.user_dim + self.genome_dim
        print(f"Expected fusion vector dimension: {self.total_dim}")

    def load_visual_features(self):
        """Load visual features extracted by ViT"""
        print("Loading visual features...")
        try:
            visual_df = pd.read_csv(self.visual_features_path)
            print(f"Loaded visual features for {len(visual_df)} movies")

            # Check if dimensions match expectations
            visual_feature_cols = [col for col in visual_df.columns if 'visual_feature' in col]
            if len(visual_feature_cols) != self.visual_dim:
                print(f"Warning: Expected {self.visual_dim} visual dimensions, but found {len(visual_feature_cols)}")

            # Ensure we have a movie_id or IMDb_ID column
            id_col = None
            for col_name in ['movie_id', 'IMDb_ID', 'movieId', 'imdbId']:
                if col_name in visual_df.columns:
                    id_col = col_name
                    break

            if id_col is None:
                print("Error: No movie ID column found in visual features")
                return None

            # Rename ID column for consistency
            visual_df = visual_df.rename(columns={id_col: 'movie_id'})

            return visual_df
        except Exception as e:
            print(f"Error loading visual features: {e}")
            return None

    def load_textual_features(self):
        """Load textual features extracted by BERT"""
        print("Loading textual features...")
        try:
            textual_df = pd.read_csv(self.textual_features_path)
            print(f"Loaded textual features for {len(textual_df)} movies")

            # Check if dimensions match expectations
            textual_feature_cols = [col for col in textual_df.columns if 'text_feature' in col]
            if len(textual_feature_cols) != self.textual_dim:
                print(f"Warning: Expected {self.textual_dim} textual dimensions, but found {len(textual_feature_cols)}")

            # Ensure we have a movie_id column
            if 'movie_id' not in textual_df.columns:
                # Try to find an appropriate ID column
                for col_name in ['IMDb_ID', 'movieId', 'imdbId']:
                    if col_name in textual_df.columns:
                        textual_df = textual_df.rename(columns={col_name: 'movie_id'})
                        break
                else:
                    print("Error: No movie ID column found in textual features")
                    return None

            return textual_df
        except Exception as e:
            print(f"Error loading textual features: {e}")
            return None

    def load_structured_features(self):
        """Load structured metadata features from MLP projection"""
        print("Loading structured metadata features...")
        try:
            structured_df = pd.read_csv(self.structured_features_path)
            print(f"Loaded structured features for {len(structured_df)} movies")

            # Check if dimensions match expectations
            structured_feature_cols = [col for col in structured_df.columns if 'movie_embed' in col]
            if len(structured_feature_cols) != self.structured_dim:
                print(f"Warning: Expected {self.structured_dim} structured dimensions, but found {len(structured_feature_cols)}")

            # Ensure we have a movieId column
            if 'movieId' not in structured_df.columns:
                print("Error: No movieId column found in structured features")
                return None

            # Rename ID column for consistency
            structured_df = structured_df.rename(columns={'movieId': 'movie_id'})

            return structured_df
        except Exception as e:
            print(f"Error loading structured features: {e}")
            return None

    def load_user_features(self):
        """Load user features from MLP projection"""
        print("Loading user features...")
        try:
            user_df = pd.read_csv(self.user_features_path)
            print(f"Loaded user features for {len(user_df)} users")

            # Check if dimensions match expectations
            user_feature_cols = [col for col in user_df.columns if 'user_embed' in col]
            if len(user_feature_cols) != self.user_dim:
                print(f"Warning: Expected {self.user_dim} user dimensions, but found {len(user_feature_cols)}")

            # Ensure we have a userId column
            if 'userId' not in user_df.columns:
                print("Error: No userId column found in user features")
                return None

            return user_df
        except Exception as e:
            print(f"Error loading user features: {e}")
            return None

    def load_genome_features(self):
        """Load tag genome features"""
        print("Loading tag genome features...")
        try:
            genome_df = pd.read_csv(self.genome_features_path)
            print(f"Loaded genome features for {len(genome_df.movieId.unique())} movies")

            # Pivot to get one row per movie, with columns for each tag
            # Assuming genome_df has movieId, tagId, relevance columns
            if all(col in genome_df.columns for col in ['movieId', 'tagId', 'relevance']):
                pivot_df = genome_df.pivot(index='movieId', columns='tagId', values='relevance')
                pivot_df = pivot_df.reset_index()

                # Rename columns for clarity
                tag_columns = {col: f'genome_tag_{col}' for col in pivot_df.columns if col != 'movieId'}
                pivot_df = pivot_df.rename(columns=tag_columns)

                genome_df = pivot_df

                # Check dimensions
                genome_feature_cols = [col for col in genome_df.columns if 'genome_tag' in col]
                if len(genome_feature_cols) != self.genome_dim:
                    print(f"Warning: Expected {self.genome_dim} genome dimensions, but found {len(genome_feature_cols)}")
            else:
                # Handle case where genome data is already pivoted
                genome_feature_cols = [col for col in genome_df.columns if col != 'movieId']
                if len(genome_feature_cols) != self.genome_dim:
                    print(f"Warning: Expected {self.genome_dim} genome dimensions, but found {len(genome_feature_cols)}")

            # Rename ID column for consistency
            genome_df = genome_df.rename(columns={'movieId': 'movie_id'})

            return genome_df
        except Exception as e:
            print(f"Error loading genome features: {e}")
            return None

    def fusion_features(self):
        """Fuse all feature sets by movie ID"""
        print("\nFusing all feature sets...")

        # Load all feature sets
        visual_df = self.load_visual_features()
        textual_df = self.load_textual_features()
        structured_df = self.load_structured_features()
        user_df = self.load_user_features()  # We'll handle this separately
        genome_df = self.load_genome_features()

        # Check if we have the minimum required features
        if visual_df is None or textual_df is None or structured_df is None:
            print("Error: Missing essential feature sets")
            return None

        # Start with movie features (those we have for each movie)
        fused_df = visual_df[['movie_id']].copy()

        # Add visual features
        visual_feature_cols = [col for col in visual_df.columns if 'visual_feature' in col]
        fused_df = pd.merge(fused_df, visual_df[['movie_id'] + visual_feature_cols], on='movie_id', how='left')

        # Add textual features
        textual_feature_cols = [col for col in textual_df.columns if 'text_feature' in col]
        fused_df = pd.merge(fused_df, textual_df[['movie_id'] + textual_feature_cols], on='movie_id', how='left')

        # Add structured features
        structured_feature_cols = [col for col in structured_df.columns if 'movie_embed' in col]
        fused_df = pd.merge(fused_df, structured_df[['movie_id'] + structured_feature_cols], on='movie_id', how='left')

        # Add genome features if available
        if genome_df is not None:
            genome_feature_cols = [col for col in genome_df.columns if col != 'movie_id']
            fused_df = pd.merge(fused_df, genome_df[['movie_id'] + genome_feature_cols], on='movie_id', how='left')

        # Fill missing values with zeros
        for col in fused_df.columns:
            if col != 'movie_id':
                fused_df[col] = fused_df[col].fillna(0)

        print(f"Created fused feature vectors for {len(fused_df)} movies")

        # Calculate actual vector dimension
        total_dims = len(fused_df.columns) - 1  # Excluding movie_id column
        print(f"Actual fusion vector dimension: {total_dims}")

        return fused_df, user_df

    def create_user_item_matrix(self, ratings_path, fused_df, user_df):
        """Create user-item matrix with ratings and features"""
        print("\nCreating user-item rating matrix...")

        try:
            # Load ratings
            ratings_df = pd.read_csv(ratings_path)
            print(f"Loaded {len(ratings_df)} ratings")

            # Ensure correct column names
            if 'userId' in ratings_df.columns:
                ratings_df = ratings_df.rename(columns={'userId': 'user_id'})
            if 'movieId' in ratings_df.columns:
                ratings_df = ratings_df.rename(columns={'movieId': 'movie_id'})

            # Create matrix with only movies for which we have features
            available_movies = fused_df['movie_id'].unique()
            valid_ratings = ratings_df[ratings_df['movie_id'].isin(available_movies)]

            print(f"Using {len(valid_ratings)} ratings for {len(available_movies)} movies")

            # Add user features if available
            if user_df is not None:
                user_feature_cols = [col for col in user_df.columns if 'user_embed' in col]
                user_df = user_df.rename(columns={'userId': 'user_id'})

                # Merge user features with ratings
                matrix_df = pd.merge(valid_ratings, user_df[['user_id'] + user_feature_cols],
                                     on='user_id', how='left')

                # Fill missing user features with zeros
                for col in user_feature_cols:
                    matrix_df[col] = matrix_df[col].fillna(0)
            else:
                matrix_df = valid_ratings.copy()

            # Merge with movie features
            movie_features = fused_df.drop(columns=['movie_id']).copy()
            movie_features.columns = [f'movie_{col}' for col in movie_features.columns]
            movie_features.insert(0, 'movie_id', fused_df['movie_id'])

            matrix_df = pd.merge(matrix_df, movie_features, on='movie_id', how='left')

            print(f"Created user-item matrix with {len(matrix_df)} entries")

            return matrix_df
        except Exception as e:
            print(f"Error creating user-item matrix: {e}")
            return None

    def save_features(self, fused_df, output_file='fused_features.csv'):
        """Save fused feature vectors to file"""
        print(f"\nSaving fused features to {output_file}")

        try:
            output_path = os.path.join(self.data_dir, output_file)
            fused_df.to_csv(output_path, index=False)
            print(f"Successfully saved {len(fused_df)} fused feature vectors")
            return True
        except Exception as e:
            print(f"Error saving fused features: {e}")
            return False

    def save_user_item_matrix(self, matrix_df, output_file='user_item_matrix.csv'):
        """Save user-item matrix to file"""
        print(f"\nSaving user-item matrix to {output_file}")

        try:
            output_path = os.path.join(self.data_dir, output_file)
            matrix_df.to_csv(output_path, index=False)
            print(f"Successfully saved user-item matrix with {len(matrix_df)} entries")
            return True
        except Exception as e:
            print(f"Error saving user-item matrix: {e}")
            return False

    def visualize_feature_importances(self, fused_df):
        """Visualize contribution of different feature types using correlation analysis"""
        print("\nAnalyzing feature importance through correlations...")

        try:
            # Get columns for each feature type
            visual_cols = [col for col in fused_df.columns if 'visual_feature' in col]
            textual_cols = [col for col in fused_df.columns if 'text_feature' in col]
            structured_cols = [col for col in fused_df.columns if 'movie_embed' in col]
            genome_cols = [col for col in fused_df.columns if 'genome_tag' in col]

            feature_types = {
                'Visual': visual_cols,
                'Textual': textual_cols,
                'Structured': structured_cols,
                'Genome': genome_cols
            }

            # Create correlation matrix between feature groups
            corr_matrix = pd.DataFrame(index=feature_types.keys(), columns=feature_types.keys())

            for type1, cols1 in feature_types.items():
                for type2, cols2 in feature_types.items():
                    if len(cols1) == 0 or len(cols2) == 0:
                        corr_matrix.loc[type1, type2] = np.nan
                        continue

                    # Compute average correlation between features of these types
                    correlations = []
                    # Sample columns if there are too many
                    sample_size = min(50, len(cols1), len(cols2))
                    cols1_sample = np.random.choice(cols1, sample_size, replace=False)
                    cols2_sample = np.random.choice(cols2, sample_size, replace=False)

                    for c1 in cols1_sample:
                        for c2 in cols2_sample:
                            if c1 != c2:  # Skip self-correlations
                                corr = fused_df[c1].corr(fused_df[c2])
                                correlations.append(abs(corr))  # Use absolute correlation

                    if correlations:
                        avg_corr = sum(correlations) / len(correlations)
                        corr_matrix.loc[type1, type2] = avg_corr
                    else:
                        corr_matrix.loc[type1, type2] = np.nan

            # Visualize
            plt.figure(figsize=(10, 8))
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=0, vmax=1)
            plt.title('Average Absolute Correlation Between Feature Types')

            # Save and show
            plt.tight_layout()
            plt.savefig(os.path.join(self.data_dir, 'feature_correlations.png'))
            print(f"Saved correlation visualization to {os.path.join(self.data_dir, 'feature_correlations.png')}")

            return corr_matrix
        except Exception as e:
            print(f"Error visualizing feature importances: {e}")
            return None

    def process_all(self, ratings_path):
        """Complete feature fusion pipeline"""
        print("=== Starting Complete Feature Fusion Pipeline ===")

        # Step 1: Fuse features
        fused_df, user_df = self.fusion_features()
        if fused_df is None:
            print("Feature fusion failed")
            return False

        # Step 2: Save fused features
        self.save_features(fused_df, 'fused_features.csv')

        # Step 3: Create user-item matrix if ratings are available
        if ratings_path:
            matrix_df = self.create_user_item_matrix(ratings_path, fused_df, user_df)
            if matrix_df is not None:
                self.save_user_item_matrix(matrix_df, 'user_item_matrix.csv')

        # Step 4: Visualize feature importances
        self.visualize_feature_importances(fused_df)

        print("=== Feature Fusion Pipeline Completed ===")
        return True


def main():
    """Main function to run the feature fusion pipeline"""
    print("=== Movie Recommendation Feature Fusion ===")

    # Set data directory
    data_dir = '.'

    # Path to ratings file
    ratings_path = os.path.join(data_dir, 'ratings.csv')

    # Create and run feature fusion
    fusion = FeatureFusion(data_dir=data_dir)
    fusion.process_all(ratings_path)

    # Display sample of the final feature vectors
    try:
        fused_df = pd.read_csv(os.path.join(data_dir, 'fused_features.csv'))
        print("\nSample of fused features (first 5 columns only):")
        sample_cols = ['movie_id'] + [col for col in fused_df.columns if col != 'movie_id'][:4]
        print(fused_df[sample_cols].head())

        print(f"\nTotal feature dimensions: {len(fused_df.columns)-1}")
        print(f"Number of movies with complete feature vectors: {len(fused_df)}")
    except Exception as e:
        print(f"Error displaying feature samples: {e}")


if __name__ == "__main__":
    main()